ğŸ§  LoRA Fine-Tuned Sentence Classifier

Fine-tuned a small language model (Phi-3.5 Mini) using Low-Rank Adaptation (LoRA) to classify English sentences as Declarative, Imperative, Interrogative, or Exclamatory.
Trained and deployed entirely on Apple MPS (macOS) with Hugging Face Transformers, PEFT, and FastAPI.

ğŸš€ Features

ğŸª¶ Lightweight Fine-Tuning â€“ Uses LoRA adapters to train efficiently on a laptop GPU (MPS).

ğŸ§© Custom Dataset â€“ 4-way sentence-type classification built from curated examples.

âš¡ Fast Local Inference â€“ Deployed with a FastAPI REST endpoint and minimal HTML front-end.

ğŸ§  Modular Design â€“ Separate scripts for data prep, training, inference, and serving.

ğŸ’» Zero Cloud Dependency â€“ Entire pipeline runs locally without CUDA or external services.

ğŸ§° Tech Stack
Area	Tools
Model	Phi-3.5 Mini Instruct

Fine-Tuning	transformers, trl, peft (LoRA)
Serving	FastAPI, uvicorn, CORS
Front-End	Vanilla HTML + Fetch API
Hardware	Apple Silicon (MPS backend)
ğŸ“¦ Setup
# clone repo
git clone https://github.com/yourusername/LoRA-fine-tune.git
cd LoRA-fine-tune

# create environment
python -m venv .lora-env
source .lora-env/bin/activate

# install dependencies
pip install -U transformers peft trl datasets accelerate fastapi uvicorn

ğŸ§ª Training
python main.py --train


This runs LoRA fine-tuning on the custom dataset (sentence_type_dataset.jsonl)
and saves the adapter weights to out-lora-mac/adapter.

ğŸ¤– Inference
python main.py --predict "What a wonderful day!"


Output:

Prediction: Exclamatory


For faster interactive use:

python serve_repl.py


or run the API:

python serve_api.py


Then open the simple web UI at http://127.0.0.1:5500

ğŸ“Š Example Predictions
Sentence	Prediction
â€œPlease open the east valve.â€	Imperative
â€œWhy is the pressure reading so high?â€	Interrogative
â€œThe pump is running smoothly.â€	Declarative
â€œWhat a wonderful surprise!â€	Exclamatory
ğŸ§© Project Structure
LoRA-fine-tune/
â”œâ”€â”€ main.py                 # entry point (train / predict)
â”œâ”€â”€ train.py                # LoRA fine-tuning pipeline
â”œâ”€â”€ inference_stable.py     # optimized inference script
â”œâ”€â”€ serve_api.py            # FastAPI server
â”œâ”€â”€ web/index.html          # minimal front-end UI
â”œâ”€â”€ sentence_type_dataset.jsonl
â””â”€â”€ out-lora-mac/adapter/   # trained adapter weights

ğŸ“˜ Description

This project demonstrates a full end-to-end fine-tuning and deployment workflow for a compact LLM.
It highlights:

Efficient parameter-tuning via LoRA

Local deployment without cloud GPUs

Reusable structure for custom AI assistants or classifiers

âœ¨ Example Use Cases

Embedded LLMs for grammar or tone detection

Domain-specific text classification with limited data

On-device AI prototypes for offline NLP tasks

ğŸ§¾ License

MIT Â© 2025 Zayed